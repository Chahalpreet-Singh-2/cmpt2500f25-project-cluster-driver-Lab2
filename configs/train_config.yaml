# Training Configuration
# Model selection
model:
  type: random_forest 
  random_state: 42
# Model-specific parameters
params:
  logistic_regression:
    max_iter: 1000
    solver: lbfgs
    C: 1.0
  random_forest:
   n_estimators: 100
   max_depth: 10
   min_samples_split: 2
   min_samples_leaf: 1
  decision_tree:
   max_depth: 10
   min_samples_split: 2
  gradient_boosting:
   n_estimators: 100
   learning_rate: 0.1
   max_depth: 5
# Training settings
training:
  test_size: 0.2
  stratify: true # Stratify by target
  tune: false # Enable hyperparameter tuning
# Hyperparameter tuning (used when tune=true)
tuning:
  cv: 5 # Cross-validation folds
  scoring: accuracy
  n_jobs: -1 # Use all CPU cores
  verbose: 1
# Parameter grids for tuning
  param_grids:
    random_forest:
     n_estimators: [50, 100, 200]
     max_depth: [10, 20, None]
     min_samples_split: [2, 5, 10]
     min_samples_leaf: [1, 2, 4]
    gradient_boosting:
     n_estimators: [50, 100, 200]
     learning_rate: [0.01, 0.1, 0.2]
     max_depth: [3, 5, 7]
# Model evaluation
evaluation:
  metrics:
    - accuracy
    - precision
    - recall
    - f1_score
    - roc_auc
  save_confusion_matrix: true
  save_classification_report: true

  train:
  feature_columns:
    - FSA_Code
    - make
    - price
    - Region
    - Most_sold_brand
    - Average_mileage
    - Average_price
    - FSA_Latitude
    - FSA_Longitude
    - Region_vehicle_sold
    - Region_dealerships
    - Most_sold_month

  categorical_columns:
    - FSA_Code
    - make
    - Region
    - Most_sold_brand

  algorithm: kprototypes       # or: kmeans (forces numeric-only fallback)
  n_clusters: 10
  init: "Huang"
  random_state: 42
  scale_numerical: true

  # optional: quick elbow/silhouette sweep for guidance
  evaluation:
    elbow_k_range: [2, 15]
    silhouette_k_range: [2, 15]

  save_model: true
  model_path: models/kprototypes_model.joblib
    
